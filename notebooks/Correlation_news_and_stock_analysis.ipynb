{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "tsla_data = pd.read_csv('../data/TSLA_historical_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0                                           headline  \\\n",
      "0                 0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1                 1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2                 2                      71 Biggest Movers From Friday   \n",
      "3                 3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4                 4  B of A Securities Maintains Neutral on Agilent...   \n",
      "...             ...                                                ...   \n",
      "1407323     1413844             Top Narrow Based Indexes For August 29   \n",
      "1407324     1413845  Recap: Wednesday's Top Percentage Gainers and ...   \n",
      "1407325     1413846  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
      "1407326     1413847  Oppenheimer Initiates China Zenix At Outperfor...   \n",
      "1407327     1413848  China Zenix Auto International Opens For Tradi...   \n",
      "\n",
      "                                                       url          publisher  \\\n",
      "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "...                                                    ...                ...   \n",
      "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
      "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
      "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
      "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
      "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
      "\n",
      "                              date stock  \n",
      "0        2020-06-05 10:30:54-04:00     A  \n",
      "1        2020-06-03 10:45:20-04:00     A  \n",
      "2        2020-05-26 04:30:07-04:00     A  \n",
      "3        2020-05-22 12:45:06-04:00     A  \n",
      "4        2020-05-22 11:38:59-04:00     A  \n",
      "...                            ...   ...  \n",
      "1407323        2011-08-29 00:00:00    ZX  \n",
      "1407324        2011-06-22 00:00:00    ZX  \n",
      "1407325        2011-06-21 00:00:00    ZX  \n",
      "1407326        2011-06-21 00:00:00    ZX  \n",
      "1407327        2011-05-12 00:00:00    ZX  \n",
      "\n",
      "[1407328 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Open        High         Low       Close   Adj Close  \\\n",
      "0     2010-06-29    1.266667    1.666667    1.169333    1.592667    1.592667   \n",
      "1     2010-06-30    1.719333    2.028000    1.553333    1.588667    1.588667   \n",
      "2     2010-07-01    1.666667    1.728000    1.351333    1.464000    1.464000   \n",
      "3     2010-07-02    1.533333    1.540000    1.247333    1.280000    1.280000   \n",
      "4     2010-07-06    1.333333    1.333333    1.055333    1.074000    1.074000   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "3540  2024-07-24  225.419998  225.990005  214.710007  215.990005  215.990005   \n",
      "3541  2024-07-25  216.800003  226.000000  216.229996  220.250000  220.250000   \n",
      "3542  2024-07-26  221.190002  222.279999  215.330002  219.800003  219.800003   \n",
      "3543  2024-07-29  224.899994  234.270004  224.699997  232.100006  232.100006   \n",
      "3544  2024-07-30  232.250000  232.410004  220.000000  222.619995  222.619995   \n",
      "\n",
      "         Volume  Dividends  Stock Splits  \n",
      "0     281494500        0.0           0.0  \n",
      "1     257806500        0.0           0.0  \n",
      "2     123282000        0.0           0.0  \n",
      "3      77097000        0.0           0.0  \n",
      "4     103003500        0.0           0.0  \n",
      "...         ...        ...           ...  \n",
      "3540  167942900        0.0           0.0  \n",
      "3541  100636500        0.0           0.0  \n",
      "3542   94604100        0.0           0.0  \n",
      "3543  129201800        0.0           0.0  \n",
      "3544  100560300        0.0           0.0  \n",
      "\n",
      "[3545 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tsla_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data to datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['date'] = pd.to_datetime(news_data['date'], format='ISO8601')\n",
    "tsla_data['Date'] = pd.to_datetime(tsla_data['Date'],utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2020-06-05 10:30:54-04:00\n",
      "1         2020-06-03 10:45:20-04:00\n",
      "2         2020-05-26 04:30:07-04:00\n",
      "3         2020-05-22 12:45:06-04:00\n",
      "4         2020-05-22 11:38:59-04:00\n",
      "                     ...           \n",
      "1407323   2011-08-29 00:00:00-04:00\n",
      "1407324   2011-06-22 00:00:00-04:00\n",
      "1407325   2011-06-21 00:00:00-04:00\n",
      "1407326   2011-06-21 00:00:00-04:00\n",
      "1407327   2011-05-12 00:00:00-04:00\n",
      "Name: date, Length: 1407328, dtype: datetime64[ns, UTC-04:00]\n"
     ]
    }
   ],
   "source": [
    "print(news_data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.00\n",
      "1          0.00\n",
      "2          0.00\n",
      "3          0.00\n",
      "4          0.00\n",
      "           ... \n",
      "1407323    0.15\n",
      "1407324    0.15\n",
      "1407325    0.00\n",
      "1407326    0.00\n",
      "1407327    0.00\n",
      "Name: sentiment, Length: 1407328, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(news_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Daily Stock Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily percentage change in closing prices to represent stock movements\n",
    "\n",
    "tsla_data['Daily_Returns'] = tsla_data['Close'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate sentiment scores if multiple articles appear on the same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment = news_data.groupby('date')['sentiment'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the datasets on the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both datasets have the same dates\n",
    "merged_data = pd.concat([daily_sentiment, tsla_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset:\n",
      "                           date  sentiment                      Date  \\\n",
      "0     2009-02-14 00:00:00-04:00   0.000000 2010-06-29 00:00:00+00:00   \n",
      "1     2009-04-27 00:00:00-04:00   0.000000 2010-06-30 00:00:00+00:00   \n",
      "2     2009-04-29 00:00:00-04:00   0.000000 2010-07-01 00:00:00+00:00   \n",
      "3     2009-05-22 00:00:00-04:00   0.000000 2010-07-02 00:00:00+00:00   \n",
      "4     2009-05-27 00:00:00-04:00   0.234091 2010-07-06 00:00:00+00:00   \n",
      "...                         ...        ...                       ...   \n",
      "39952 2020-06-11 16:49:41-04:00   0.000000                       NaT   \n",
      "39953 2020-06-11 16:51:33-04:00   0.000000                       NaT   \n",
      "39954 2020-06-11 17:01:39-04:00  -0.085185                       NaT   \n",
      "39955 2020-06-11 17:11:20-04:00   0.000000                       NaT   \n",
      "39956 2020-06-11 17:12:35-04:00   0.000000                       NaT   \n",
      "\n",
      "           Open      High       Low     Close  Adj Close       Volume  \\\n",
      "0      1.266667  1.666667  1.169333  1.592667   1.592667  281494500.0   \n",
      "1      1.719333  2.028000  1.553333  1.588667   1.588667  257806500.0   \n",
      "2      1.666667  1.728000  1.351333  1.464000   1.464000  123282000.0   \n",
      "3      1.533333  1.540000  1.247333  1.280000   1.280000   77097000.0   \n",
      "4      1.333333  1.333333  1.055333  1.074000   1.074000  103003500.0   \n",
      "...         ...       ...       ...       ...        ...          ...   \n",
      "39952       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39953       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39954       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39955       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39956       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "\n",
      "       Dividends  Stock Splits  Daily_Returns  \n",
      "0            0.0           0.0            NaN  \n",
      "1            0.0           0.0      -0.251148  \n",
      "2            0.0           0.0      -7.847274  \n",
      "3            0.0           0.0     -12.568307  \n",
      "4            0.0           0.0     -16.093748  \n",
      "...          ...           ...            ...  \n",
      "39952        NaN           NaN            NaN  \n",
      "39953        NaN           NaN            NaN  \n",
      "39954        NaN           NaN            NaN  \n",
      "39955        NaN           NaN            NaN  \n",
      "39956        NaN           NaN            NaN  \n",
      "\n",
      "[39957 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged dataset:\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in sentiment: 0\n",
      "Missing values in Daily_Returns: 36413\n",
      "Infinite values in sentiment: 0\n",
      "Infinite values in Daily_Returns: 0\n"
     ]
    }
   ],
   "source": [
    "missing_sentiment = merged_data['sentiment'].isnull().sum()\n",
    "missing_returns = merged_data['Daily_Returns'].isnull().sum()\n",
    "print(\"Missing values in sentiment:\", missing_sentiment)\n",
    "print(\"Missing values in Daily_Returns:\", missing_returns)\n",
    "\n",
    "# Check for infinite values\n",
    "infinite_sentiment = np.isinf(merged_data['sentiment']).sum()\n",
    "infinite_returns = np.isinf(merged_data['Daily_Returns']).sum()\n",
    "print(\"Infinite values in sentiment:\", infinite_sentiment)\n",
    "print(\"Infinite values in Daily_Returns:\", infinite_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset:\n",
      "                           date  sentiment                      Date  \\\n",
      "0     2009-02-14 00:00:00-04:00   0.000000 2010-06-29 00:00:00+00:00   \n",
      "1     2009-04-27 00:00:00-04:00   0.000000 2010-06-30 00:00:00+00:00   \n",
      "2     2009-04-29 00:00:00-04:00   0.000000 2010-07-01 00:00:00+00:00   \n",
      "3     2009-05-22 00:00:00-04:00   0.000000 2010-07-02 00:00:00+00:00   \n",
      "4     2009-05-27 00:00:00-04:00   0.234091 2010-07-06 00:00:00+00:00   \n",
      "...                         ...        ...                       ...   \n",
      "39952 2020-06-11 16:49:41-04:00   0.000000                       NaT   \n",
      "39953 2020-06-11 16:51:33-04:00   0.000000                       NaT   \n",
      "39954 2020-06-11 17:01:39-04:00  -0.085185                       NaT   \n",
      "39955 2020-06-11 17:11:20-04:00   0.000000                       NaT   \n",
      "39956 2020-06-11 17:12:35-04:00   0.000000                       NaT   \n",
      "\n",
      "           Open      High       Low     Close  Adj Close       Volume  \\\n",
      "0      1.266667  1.666667  1.169333  1.592667   1.592667  281494500.0   \n",
      "1      1.719333  2.028000  1.553333  1.588667   1.588667  257806500.0   \n",
      "2      1.666667  1.728000  1.351333  1.464000   1.464000  123282000.0   \n",
      "3      1.533333  1.540000  1.247333  1.280000   1.280000   77097000.0   \n",
      "4      1.333333  1.333333  1.055333  1.074000   1.074000  103003500.0   \n",
      "...         ...       ...       ...       ...        ...          ...   \n",
      "39952       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39953       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39954       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39955       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "39956       NaN       NaN       NaN       NaN        NaN          NaN   \n",
      "\n",
      "       Dividends  Stock Splits  Daily_Returns  \n",
      "0            0.0           0.0            NaN  \n",
      "1            0.0           0.0      -0.251148  \n",
      "2            0.0           0.0      -7.847274  \n",
      "3            0.0           0.0     -12.568307  \n",
      "4            0.0           0.0     -16.093748  \n",
      "...          ...           ...            ...  \n",
      "39952        NaN           NaN            NaN  \n",
      "39953        NaN           NaN            NaN  \n",
      "39954        NaN           NaN            NaN  \n",
      "39955        NaN           NaN            NaN  \n",
      "39956        NaN           NaN            NaN  \n",
      "\n",
      "[39957 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Merged dataset:\")\n",
    "print(merged_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39957\n",
      "39957\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_data['sentiment']))\n",
    "print(len(merged_data['Daily_Returns']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Check for NaN or infinite values in the arrays\n",
    "nan_mask = np.isnan(merged_data['sentiment']) | np.isnan(merged_data['Daily_Returns'])\n",
    "inf_mask = np.isinf(merged_data['sentiment']) | np.isinf(merged_data['Daily_Returns'])\n",
    "\n",
    "# Combine NaN and infinite masks\n",
    "invalid_mask = nan_mask | inf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid values from both arrays\n",
    "clean_sentiment = merged_data['sentiment'][~invalid_mask]\n",
    "clean_returns = merged_data['Daily_Returns'][~invalid_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Calculate correlation between sentiment and daily stock returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sentiment and daily stock returns: 0.04234996262396389\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correlation = merged_data['sentiment'].corr(merged_data['Daily_Returns'])\n",
    "\n",
    "print(f\"Correlation between sentiment and daily stock returns: {correlation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_firew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
